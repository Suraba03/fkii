{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курсовая работа по машинному обучению: анализ и классификация данных Titanic\n",
    "\n",
    "## 0. Введение\n",
    "\n",
    "### Описание датасета\n",
    "Датасет Titanic представляет собой исторические данные о пассажирах печально известного рейса Титаника. Целью анализа является предсказание выживаемости пассажиров на основе доступной информации, такой как возраст, пол, класс билета и другие характеристики.\n",
    "\n",
    "**Источник данных:** [Kaggle Titanic Dataset](https://www.kaggle.com/c/titanic/data)\n",
    "\n",
    "**Цель задачи:**\n",
    "- Построить модель бинарной классификации для предсказания выживаемости пассажиров.\n",
    "\n",
    "**Пример данных:**\n",
    "\n",
    "```plaintext\n",
    "| PassengerId | Survived | Pclass | Name              | Sex    | Age | SibSp | Parch | Ticket | Fare   | Cabin | Embarked |\n",
    "|-------------|----------|--------|-------------------|--------|-----|-------|-------|--------|--------|-------|----------|\n",
    "| 1           | 0        | 3      | Braund, Mr. Owen | male   | 22  | 1     | 0     | A/5 21171 | 7.25 | NaN   | S        |\n",
    "| 2           | 1        | 1      | Cumings, Mrs. J  | female | 38  | 1     | 0     | PC 17599 | 71.28 | C85   | C        |\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API для загрузки и предварительного анализа данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd3048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TitanicDatasetLoader:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.filepath)\n",
    "        return self.data\n",
    "\n",
    "    def get_sample(self, n=5):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Данные не загружены. Используйте метод load_data().\")\n",
    "        return self.data.sample(n)\n",
    "\n",
    "    def split_data(self, test_size=0.2, random_state=42):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Данные не загружены. Используйте метод load_data().\")\n",
    "        X = self.data.drop(columns=['Survived'])\n",
    "        y = self.data['Survived']\n",
    "        return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Пример использования\n",
    "loader = TitanicDatasetLoader(\"titanic.csv\")\n",
    "data = loader.load_data()\n",
    "print(loader.get_sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Исследование данных\n",
    "\n",
    "### Статистика по данным\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной анализ данных\n",
    "print(\"Размер данных:\", data.shape)\n",
    "print(\"Количество пропусков:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Типы данных\n",
    "print(\"Типы данных:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Распределение классов\n",
    "print(\"Распределение классов выживаемости:\")\n",
    "print(data['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Выбор алгоритма\n",
    "\n",
    "### Постановка задачи\n",
    "Мы решаем задачу бинарной классификации: предсказать, выжил пассажир или нет (Survived).\n",
    "\n",
    "### Пример алгоритма\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c94f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "# Список моделей\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42, probability=True),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Функция для бутстрап-оценки\n",
    "\n",
    "def bootstrap_evaluation(model, X_train, y_train, X_test, y_test, n_iterations=100):\n",
    "    scores = []\n",
    "    for _ in range(n_iterations):\n",
    "        X_resampled, y_resampled = resample(X_train, y_train)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Сравнение моделей\n",
    "for name, model in models.items():\n",
    "    mean_score, std_score = bootstrap_evaluation(model, X_train, y_train, X_test, y_test)\n",
    "    print(f\"{name}: Точность = {mean_score:.3f} ± {std_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление выбросов и повторное обучение\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Удаление выбросов\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "outlier_mask = iso_forest.fit_predict(X_train) == 1\n",
    "X_train_cleaned = X_train[outlier_mask]\n",
    "y_train_cleaned = y_train[outlier_mask]\n",
    "\n",
    "# Обучение модели на очищенных данных\n",
    "model_cleaned = RandomForestClassifier(random_state=42)\n",
    "model_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# Инференс\n",
    "predictions_cleaned = model_cleaned.predict(X_test)\n",
    "print(\"Точность модели после удаления выбросов:\", accuracy_score(y_test, predictions_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение на данных со сниженной размерностью\n",
    "\n",
    "# Обучение модели на данных после PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfad2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели на данных после PCA\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "model_pca = RandomForestClassifier(random_state=42)\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "predictions_pca = model_pca.predict(X_test_pca)\n",
    "print(\"Точность модели на данных со сниженной размерностью:\", accuracy_score(y_test, predictions_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение различных алгоритмов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee3cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "# Список моделей\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42, probability=True),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Функция для бутстрап-оценки\n",
    "\n",
    "def bootstrap_evaluation(model, X_train, y_train, X_test, y_test, n_iterations=100):\n",
    "    scores = []\n",
    "    for _ in range(n_iterations):\n",
    "        X_resampled, y_resampled = resample(X_train, y_train)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Сравнение моделей\n",
    "for name, model in models.items():\n",
    "    mean_score, std_score = bootstrap_evaluation(model, X_train, y_train, X_test, y_test)\n",
    "    print(f\"{name}: Точность = {mean_score:.3f} ± {std_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Кластеризация и понижение размерности\n",
    "\n",
    "### PCA для визуализации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Понижение размерности\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, cmap='viridis')\n",
    "plt.title('PCA визуализация данных')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Аномалии\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Поиск аномалий\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "iso_forest.fit(X_train)\n",
    "anomalies = iso_forest.predict(X_train)\n",
    "\n",
    "print(\"Количество аномалий:\", sum(anomalies == -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ML-systems design\n",
    "\n",
    "### Возможности продакшн-системы\n",
    "- Автоматическое предсказание выживаемости пассажиров на основе данных о рейсе.\n",
    "- Пример использования: прогнозирование рисков для транспортных систем.\n",
    "\n",
    "### Преимущества и недостатки\n",
    "**Преимущества:**\n",
    "- Простота использования.\n",
    "- Доступность данных для обучения.\n",
    "\n",
    "**Недостатки:**\n",
    "- Ограниченность характеристик.\n",
    "- Необъективность исторических данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "Данная курсовая работа демонстрирует основные этапы анализа данных, выбора модели и подготовки системы для задач машинного обучения. Датасет Titanic является удобным инструментом для обучения, но имеет ограничения, которые необходимо учитывать при использовании в реальных системах."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_val",
   "language": "python",
   "name": "llm_val"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
